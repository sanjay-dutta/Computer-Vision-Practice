# Gaze Detection Using Computer Vision & YOLO11

This repository provides a concise overview and starter structure for understanding and implementing **gaze detection** using modern computer vision techniques. The project is inspired by the principles described in *â€œGaze Detection with Computer Vision & YOLO11 | Ultralyticsâ€* and highlights how object detection and pose estimation models can support eye-tracking and gaze-estimation tasks.

---

## ğŸ“Œ Summary of Gaze Detection

Gaze detection is a computer vision method used to determine where a person is looking by analyzing **eye movements, facial features, and head orientation**. Traditional infrared-based eye-tracking systems required specialized hardware, but advancements in AI now enable accurate gaze estimation with regular cameras.

Models like **Ultralytics YOLO11** can detect key facial regions such as **eyes, pupils, and head pose**, which can then be fed into specialized gaze-estimation networks (e.g., GazeNet) to compute the direction of gaze. These techniques support applications in **driver monitoring**, **gaming analytics**, **psychology research**, and **humanâ€“computer interaction**.

Although powerful and increasingly accessible, gaze detection faces challenges including **lighting sensitivity**, **occlusions**, **privacy concerns**, and **computational requirements** for real-time predictions.

---

## ğŸš€ Key Features

* Detection of faces, eyes, and pupils using YOLO11
* Foundation for integrating deep gaze-estimation models
* Works with standard webcams (no IR hardware needed)
* Applicable to real-world scenarios such as:

  * Driver attention monitoring
  * Gaming and eSports performance analysis
  * Cognitive and psychological studies
  * Humanâ€“computer interaction (HCI)

---

## ğŸ“‚ Project Structure (Suggested)

```
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ detect_faces.py
â”‚   â”œâ”€â”€ detect_eyes.py
â”‚   â”œâ”€â”€ gaze_estimation.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yolov11n.pt
â”‚   â””â”€â”€ gazenet_pretrained.pt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_images/
â”‚   â””â”€â”€ videos/
â””â”€â”€ notebooks/
    â””â”€â”€ demo.ipynb
```

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/gaze-detection-yolo11.git
cd gaze-detection-yolo11

pip install -r requirements.txt
```

---

## â–¶ï¸ Usage

### **1. Run face + eye detection**

```bash
python src/detect_eyes.py --source data/sample_images/
```

### **2. Run gaze estimation**

```bash
python src/gaze_estimation.py --source data/videos/demo.mp4
```

### **3. Jupyter Notebook Demo**

```
notebooks/demo.ipynb
```

---

## ğŸ§  How It Works

1. **YOLO11** detects face, eyes, and pupils
2. **Head pose estimation** refines directional context
3. A deep gaze-estimation model (e.g., GazeNet) predicts gaze direction
4. Visual overlay shows where the user is looking

---

## ğŸ“Œ Applications

* Driver monitoring & safety systems
* eSports & gaming performance analysis
* Psychology & cognitive research
* Retail & marketing attention studies
* VR/AR interaction systems

---
