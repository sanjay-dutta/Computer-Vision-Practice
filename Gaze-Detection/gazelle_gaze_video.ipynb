{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUMlH-kZ_ZUk",
        "outputId": "58ece2a2-b8fb-43e9-8e13-3ec489daefa6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnRw4-Q2I48O",
        "outputId": "57fc4bf4-1e7c-44a1-fe99-222a79633e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: retina-face in /usr/local/lib/python3.12/dist-packages (0.0.17)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from retina-face) (2.0.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from retina-face) (5.2.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from retina-face) (11.3.0)\n",
            "Requirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.12/dist-packages (from retina-face) (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from retina-face) (2.19.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->retina-face) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.9.0->retina-face) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.9.0->retina-face) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.9.0->retina-face) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (3.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=3.10.1->retina-face) (2.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (1.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.9.0->retina-face) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.9.0->retina-face) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=1.9.0->retina-face) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install retina-face"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from retinaface import RetinaFace\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "class VideoGazeAnalyzer:\n",
        "    def __init__(self, use_cuda=True):\n",
        "        self.device = 'cuda' if use_cuda and torch.cuda.is_available() else 'cpu'\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Load Gazelle model\n",
        "        self.model, self.transform = torch.hub.load('fkryan/gazelle', 'gazelle_dinov2_vitl14_inout')\n",
        "        self.model.eval()\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Colors for visualization\n",
        "        self.colors = ['lime', 'tomato', 'cyan', 'fuchsia', 'yellow']\n",
        "\n",
        "    def process_frame(self, frame):\n",
        "        \"\"\"Process a single frame and return the visualization\"\"\"\n",
        "        # Convert BGR to RGB\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(frame_rgb)\n",
        "        width, height = image.size\n",
        "\n",
        "        # Detect faces\n",
        "        resp = RetinaFace.detect_faces(frame_rgb)\n",
        "        if not isinstance(resp, dict):\n",
        "            return frame  # Return original frame if no faces detected\n",
        "\n",
        "        # Extract bounding boxes\n",
        "        bboxes = [resp[key]['facial_area'] for key in resp.keys()]\n",
        "        norm_bboxes = [[np.array(bbox) / np.array([width, height, width, height])\n",
        "                       for bbox in bboxes]]\n",
        "\n",
        "        # Prepare input for Gazelle\n",
        "        img_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
        "        input_data = {\n",
        "            \"images\": img_tensor,\n",
        "            \"bboxes\": norm_bboxes\n",
        "        }\n",
        "\n",
        "        # Get model predictions\n",
        "        with torch.no_grad():\n",
        "            output = self.model(input_data)\n",
        "\n",
        "        # Visualize results\n",
        "        result_image = self.visualize_all(\n",
        "            image,\n",
        "            output['heatmap'][0],\n",
        "            norm_bboxes[0],\n",
        "            output['inout'][0] if output['inout'] is not None else None\n",
        "        )\n",
        "\n",
        "        # Convert back to BGR for OpenCV\n",
        "        result_array = np.array(result_image)\n",
        "        return cv2.cvtColor(result_array, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    def visualize_all(self, pil_image, heatmaps, bboxes, inout_scores, inout_thresh=0.5):\n",
        "        \"\"\"Visualize all detected faces and their gaze directions\"\"\"\n",
        "        overlay_image = pil_image.convert(\"RGBA\")\n",
        "        draw = ImageDraw.Draw(overlay_image)\n",
        "        width, height = pil_image.size\n",
        "\n",
        "        for i in range(len(bboxes)):\n",
        "            bbox = bboxes[i]\n",
        "            xmin, ymin, xmax, ymax = bbox\n",
        "            color = self.colors[i % len(self.colors)]\n",
        "\n",
        "            # Draw face bounding box\n",
        "            draw.rectangle(\n",
        "                [xmin * width, ymin * height, xmax * width, ymax * height],\n",
        "                outline=color,\n",
        "                width=int(min(width, height) * 0.01)\n",
        "            )\n",
        "\n",
        "            if inout_scores is not None:\n",
        "                inout_score = inout_scores[i]\n",
        "\n",
        "                # Draw in-frame score\n",
        "                text = f\"in-frame: {inout_score:.2f}\"\n",
        "                text_y = ymax * height + int(height * 0.01)\n",
        "                draw.text(\n",
        "                    (xmin * width, text_y),\n",
        "                    text,\n",
        "                    fill=color,\n",
        "                    font=None  # Using default font\n",
        "                )\n",
        "\n",
        "                # Draw gaze direction if looking in-frame\n",
        "                if inout_score > inout_thresh:\n",
        "                    heatmap = heatmaps[i]\n",
        "                    heatmap_np = heatmap.detach().cpu().numpy()\n",
        "                    max_index = np.unravel_index(np.argmax(heatmap_np), heatmap_np.shape)\n",
        "\n",
        "                    # Calculate gaze target and face center\n",
        "                    gaze_target_x = max_index[1] / heatmap_np.shape[1] * width\n",
        "                    gaze_target_y = max_index[0] / heatmap_np.shape[0] * height\n",
        "                    bbox_center_x = ((xmin + xmax) / 2) * width\n",
        "                    bbox_center_y = ((ymin + ymax) / 2) * height\n",
        "\n",
        "                    # Draw gaze target point and line\n",
        "                    draw.ellipse(\n",
        "                        [(gaze_target_x-5, gaze_target_y-5),\n",
        "                         (gaze_target_x+5, gaze_target_y+5)],\n",
        "                        fill=color,\n",
        "                        width=int(0.005*min(width, height))\n",
        "                    )\n",
        "                    draw.line(\n",
        "                        [(bbox_center_x, bbox_center_y),\n",
        "                         (gaze_target_x, gaze_target_y)],\n",
        "                        fill=color,\n",
        "                        width=int(0.005*min(width, height))\n",
        "                    )\n",
        "\n",
        "        # Convert to RGB for OpenCV compatibility\n",
        "        return overlay_image.convert('RGB')\n",
        "\n",
        "    def process_video(self, input_path, output_path, start_time=0, duration=None):\n",
        "        \"\"\"Process a video file and save the result\"\"\"\n",
        "        # Open video file\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "        # Get video properties\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        # Calculate start and end frames\n",
        "        start_frame = int(start_time * fps)\n",
        "        if duration:\n",
        "            end_frame = start_frame + int(duration * fps)\n",
        "        else:\n",
        "            end_frame = total_frames\n",
        "\n",
        "        # Set up video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(\n",
        "            output_path,\n",
        "            fourcc,\n",
        "            fps,\n",
        "            (frame_width, frame_height)\n",
        "        )\n",
        "\n",
        "        # Seek to start frame\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "        try:\n",
        "            with tqdm(total=end_frame-start_frame) as pbar:\n",
        "                frame_count = start_frame\n",
        "                while cap.isOpened() and frame_count < end_frame:\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret:\n",
        "                        break\n",
        "\n",
        "                    # Process frame\n",
        "                    processed_frame = self.process_frame(frame)\n",
        "                    out.write(processed_frame)\n",
        "\n",
        "                    frame_count += 1\n",
        "                    pbar.update(1)\n",
        "\n",
        "        finally:\n",
        "            # Clean up\n",
        "            cap.release()\n",
        "            out.release()\n",
        "            cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "rNzv4AKbI_XL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "analyzer = VideoGazeAnalyzer()\n",
        "\n",
        "# Process a video file\n",
        "input_video = \"/content/video.mp4\"  # Replace with your video path\n",
        "output_video = \"output_video.mp4\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzbkV20bJGvF",
        "outputId": "b5ffa441-8614-499a-c07a-42ac0cafb337"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/fkryan_gazelle_main\n",
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process 10 seconds starting from 5 seconds into the video\n",
        "analyzer.process_video(\n",
        "    input_video,\n",
        "    output_video,\n",
        "    start_time=5,  # Start 5 seconds in\n",
        "    duration=10    # Process 10 seconds\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ylhf9XsJMO_",
        "outputId": "65a80e0c-e71d-446e-c11a-37f44ea53705"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/250 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-11-15 10:18:42 - Directory /root/.deepface created\n",
            "25-11-15 10:18:42 - Directory /root/.deepface/weights created\n",
            "25-11-15 10:18:42 - retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "\n",
            "  0%|          | 0.00/119M [00:00<?, ?B/s]\u001b[A\n",
            "  9%|▉         | 11.0M/119M [00:00<00:01, 89.2MB/s]\u001b[A\n",
            " 20%|██        | 24.1M/119M [00:00<00:00, 108MB/s] \u001b[A\n",
            " 36%|███▌      | 42.5M/119M [00:00<00:00, 117MB/s]\u001b[A\n",
            " 53%|█████▎    | 62.4M/119M [00:00<00:00, 144MB/s]\u001b[A\n",
            " 65%|██████▌   | 77.6M/119M [00:00<00:00, 126MB/s]\u001b[A\n",
            " 80%|███████▉  | 94.9M/119M [00:00<00:00, 123MB/s]\u001b[A\n",
            "100%|██████████| 119M/119M [00:01<00:00, 107MB/s]\n",
            "100%|██████████| 250/250 [03:25<00:00,  1.22it/s]\n"
          ]
        }
      ]
    }
  ]
}